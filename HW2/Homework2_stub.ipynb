{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dbcb905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import urllib\n",
    "import scipy.optimize\n",
    "import random\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import gzip\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "94e03340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8bbbc2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assertFloat(x):\n",
    "    assert type(float(x)) == float\n",
    "\n",
    "def assertFloatList(items, N):\n",
    "    assert len(items) == N\n",
    "    assert [type(float(x)) for x in items] == [float]*N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "85c00feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"5year.arff\", 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6fad4389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and parse the data\n",
    "while not '@data' in f.readline():\n",
    "    pass\n",
    "\n",
    "dataset = []\n",
    "for l in f:\n",
    "    if '?' in l: # Missing entry\n",
    "        continue\n",
    "    l = l.split(',')\n",
    "    values = [1] + [float(x) for x in l]\n",
    "    values[-1] = values[-1] > 0 # Convert to bool\n",
    "    dataset.append(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7691e3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [d[:-1] for d in dataset]\n",
    "y = [d[-1] for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "03249990",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = {} # Your answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a31a5b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, y):\n",
    "    correct = sum (p == actual for p, actual in zip(predictions, y))\n",
    "    return correct / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "83974166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BER(predictions, y):\n",
    "    TN, FP, FN, TP = confusion_matrix(y, predictions).ravel()\n",
    "    return 0.5 * (FP/(TN+FP) + FN/(TP+FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5e78a6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f59633dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = linear_model.LogisticRegression(C=1)\n",
    "mod.fit(X,y)\n",
    "\n",
    "pred = mod.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d68bb169",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc1 = accuracy(pred,y)\n",
    "ber1 = BER(pred,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "033a6c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q1'] = [acc1, ber1] # Accuracy and balanced error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e75988a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q1'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "30482ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bc8f8282",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = linear_model.LogisticRegression(C=1, class_weight='balanced')\n",
    "mod.fit(X,y)\n",
    "\n",
    "pred = mod.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e99274d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc2 = accuracy(pred,y)\n",
    "ber2 = BER(pred,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "de8d6195",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q2'] = [acc2, ber2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8a90cd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q2'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e1fa1ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "55d4beff",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(3)\n",
    "random.shuffle(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d19c0c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [d[:-1] for d in dataset]\n",
    "y = [d[-1] for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "18d5fd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xvalid, Xtest = X[:len(X)//2], X[len(X)//2:(3*len(X))//4], X[(3*len(X))//4:]\n",
    "ytrain, yvalid, ytest = y[:len(X)//2], y[len(X)//2:(3*len(X))//4], y[(3*len(X))//4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6d66f07c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1515, 758, 758)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Xtrain), len(Xvalid), len(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "647021ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = linear_model.LogisticRegression(C=1, class_weight='balanced')\n",
    "mod.fit(Xtrain,ytrain)\n",
    "\n",
    "pred = mod.predict(Xtrain)\n",
    "berTrain = BER(pred, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b97a9bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.fit(Xvalid, yvalid)\n",
    "pred = mod.predict(Xvalid)\n",
    "berValid = BER(pred, yvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "284f1777",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.fit(Xtest, ytest)\n",
    "pred = mod.predict(Xtest)\n",
    "berTest = BER(pred, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0bb40dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q3'] = [berTrain, berValid, berTest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9e0ece86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.29287226079549855, 0.31782645215481037, 0.21056751467710372]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assertFloatList(answers['Q3'], 3)\n",
    "\n",
    "answers['Q3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "81d44cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5ff0daca",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_values = [10 ** i for i in range (-4, 5)] # from 10^-4 to 10^4\n",
    "berList = []\n",
    "for C in C_values:\n",
    "    model = linear_model.LogisticRegression(C=C, class_weight = 'balanced')\n",
    "    model.fit(Xtrain, ytrain)\n",
    "    pred = model.predict(Xvalid)\n",
    "    berList.append(BER(pred, yvalid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3c96b655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.32677521483491634,\n",
       " 0.31931252826775214,\n",
       " 0.32948891904115785,\n",
       " 0.3233830845771144,\n",
       " 0.3159203980099502,\n",
       " 0.3111714156490276,\n",
       " 0.2955030044582283,\n",
       " 0.29618143050978873,\n",
       " 0.29618143050978873]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers['Q4'] = berList\n",
    "berList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f55f3d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q4'], 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8b455b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2a80d25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ber5 = min(berList)\n",
    "bestC = C_values[berList.index(ber5)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "62bdaa25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100, 0.2955030044582283]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers['Q5'] = [bestC, ber5]\n",
    "\n",
    "answers['Q5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b8cafe6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q5'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fcbc2e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ace19c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = gzip.open(\"young_adult_10000.json.gz\")\n",
    "dataset = []\n",
    "for l in f:\n",
    "    dataset.append(eval(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "06598b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_id': '8842281e1d1347389f2ab93d60773d4d',\n",
       " 'book_id': '2767052',\n",
       " 'review_id': '248c011811e945eca861b5c31a549291',\n",
       " 'rating': 5,\n",
       " 'review_text': \"I cracked and finally picked this up. Very enjoyable quick read - couldn't put it down - it was like crack. \\n I'm a bit bothered by the lack of backstory of how Panem and the Hunger Games come about. It is just kind of explained away in a few paragraphs and we are left to accept this very strange world where teenagers are pitted into an arena each year to kill each other? I was expecting it because I've seen Battle Royale, but I would have appreciated knowing more of the backstory of how the world could have come into such a odd state. \\n I suppose what makes a book like this interesting is thinking about the strategy of it all. The players are going to be statistically encouraged to band together because they will last longer that way, but by definition of course any partnership will be broken, and the drama of how that unfolds is always interesting and full of friendships broken and betrayal. Each character approached the game in their own way. Some banded together in larger coalitions, some were loners initially and banded together later. And some were just loners, like Foxface. A lot depended on your survival skill: could you find food and water on your own? Self-dependence is highly valued - and of course our hero was strong there. \\n All in all, a fun read, but I feel kind of dirty for having read it.\",\n",
       " 'date_added': 'Wed Jan 13 13:38:25 -0800 2010',\n",
       " 'date_updated': 'Wed Mar 22 11:46:36 -0700 2017',\n",
       " 'read_at': 'Sun Mar 25 00:00:00 -0700 2012',\n",
       " 'started_at': 'Fri Mar 23 00:00:00 -0700 2012',\n",
       " 'n_votes': 24,\n",
       " 'n_comments': 25}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataTrain = dataset[:9000]\n",
    "dataTest = dataset[9000:]\n",
    "dataTrain[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4209458b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some data structures you might want\n",
    "\n",
    "usersPerItem = defaultdict(set) # Maps an item to the users who rated it\n",
    "itemsPerUser = defaultdict(set) # Maps a user to the items that they rated\n",
    "reviewsPerUser = defaultdict(list)\n",
    "reviewsPerItem = defaultdict(list)\n",
    "ratingDict = {} # To retrieve a rating for a specific user/item pair\n",
    "\n",
    "for d in dataTrain:\n",
    "    user = d[\"user_id\"]\n",
    "    item = d[\"book_id\"]\n",
    "    rating = d[\"rating\"]\n",
    "\n",
    "    usersPerItem[item].add(user)\n",
    "    itemsPerUser[user].add(item)\n",
    "    reviewsPerUser[user].append(d)\n",
    "    reviewsPerItem[item].append(d)\n",
    "\n",
    "    ratingDict[(user, item)] = rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "03c90f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(s1, s2):\n",
    "    intersection = len(s1 & s2)\n",
    "    union = len(s1 | s2)\n",
    "    return intersection / union if union else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "25bfacf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostSimilar(i, N):\n",
    "    simlilarity = []\n",
    "\n",
    "    # set of users who rated item i\n",
    "    target_users = usersPerItem[i]\n",
    "\n",
    "    for item, users in usersPerItem.items():\n",
    "        if item != i:\n",
    "            sim = Jaccard(target_users, users)\n",
    "            simlilarity.append((sim, item))\n",
    "\n",
    "    most_simiar_items = sorted(simlilarity, reverse=True)[:N]\n",
    "    return most_simiar_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2652a90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q6'] = mostSimilar('2767052', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "35457af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(answers['Q6']) == 10\n",
    "assertFloatList([x[0] for x in answers['Q6']], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "69798ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20e389e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9a3a4f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_ratings = {item: sum([review['rating'] for review in reviews]) / len(reviews) for item, reviews in reviewsPerItem.items()}\n",
    "\n",
    "def predict_rating(user, item):\n",
    "    if item not in average_ratings:\n",
    "        return sum(average_ratings.values()) / len(average_ratings)\n",
    "    numerator, denominator = 0, 0\n",
    "\n",
    "    # Loop over items the user has rated\n",
    "    for j in itemsPerUser[user] - {item}:\n",
    "        if j in average_ratings:  # Only consider items with an average rating\n",
    "            sim = Jaccard(usersPerItem[item], usersPerItem[j])\n",
    "            numerator += (ratingDict[(user, j)] - average_ratings[j]) * sim\n",
    "            denominator += sim\n",
    "    \n",
    "    # the final predicted rating\n",
    "    if denominator == 0:\n",
    "        return average_ratings[item]  # If no similar items, use item's average rating\n",
    "    else:\n",
    "        return average_ratings[item] + numerator / denominator\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5fb4cacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(data):\n",
    "    mse = 0\n",
    "    for d in data:\n",
    "        user, item, actual_rating = d[\"user_id\"], d[\"book_id\"], d[\"rating\"]\n",
    "        predicted_rating = predict_rating(user, item)\n",
    "        mse += (predicted_rating - actual_rating) ** 2\n",
    "    return mse / len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0e3f9a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse7 = MSE(dataTest)\n",
    "answers['Q7'] = mse7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f7d294f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers['Q7'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "088d0836",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "781abe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_ratings_user = {user: sum([review['rating'] for review in reviews]) / len(reviews) for user, reviews in reviewsPerUser.items()}\n",
    "\n",
    "def predict_rating(u, i):\n",
    "    if u not in average_ratings_user:\n",
    "        return sum(average_ratings_user.values()) / len(average_ratings_user)\n",
    "    \n",
    "    numerator, denominator = 0, 0\n",
    "\n",
    "    for v in usersPerItem[item] - {user}:\n",
    "        if v in average_ratings_user:  # Only consider items with an average rating\n",
    "            sim = Jaccard(itemsPerUser[user], itemsPerUser[v])\n",
    "            numerator += (ratingDict[(v, item)] - average_ratings_user[v]) * sim\n",
    "            denominator += sim\n",
    "    \n",
    "    # final calculation\n",
    "    if denominator == 0:\n",
    "        return average_ratings_user[user]  # If no similar items, use item's average rating\n",
    "    else:\n",
    "        return average_ratings_user[user] + numerator / denominator\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2461deb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse8 = MSE(dataTest)\n",
    "answers['Q8'] = mse8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "def088ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers['Q8'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f534c8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"answers_hw2.txt\", 'w')\n",
    "f.write(str(answers) + '\\n')\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
