{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d545425e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy\n",
    "import random\n",
    "import gzip\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d577aff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e74ac91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assertFloat(x): # Checks that an answer is a float\n",
    "    assert type(float(x)) == float\n",
    "\n",
    "def assertFloatList(items, N):\n",
    "    assert len(items) == N\n",
    "    assert [type(float(x)) for x in items] == [float]*N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1a7911bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = gzip.open(\"young_adult_10000.json.gz\")\n",
    "dataset = []\n",
    "for l in f:\n",
    "    dataset.append(json.loads(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85100ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e716aa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = {} # Put your answers to each question in this dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2c286a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2a260695",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fea5f8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(datum):\n",
    "    # your implementation\n",
    "    return[1, datum['review_text'].count('!')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8f00dea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [feature(d) for d in dataset]\n",
    "Y = [d['rating'] for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f11f8b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta, residual, rank, s = numpy.linalg.lstsq(X, Y)\n",
    "\n",
    "y_pred = X @ theta\n",
    "theta0, theta1, mse = theta[0], theta[1], numpy.mean((Y - y_pred)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "51581a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q1'] = [theta0, theta1, mse]\n",
    "assertFloatList(answers['Q1'], 3) # Check the format of your answer (three floats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8b84731b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "982ea2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(datum):\n",
    "    return [1, datum['review_text'].count('!'), len(datum['review_text'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cda70702",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [feature(d) for d in dataset]\n",
    "Y = [d['rating'] for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "56957064",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta, residual, rank, s = numpy.linalg.lstsq(X, Y)\n",
    "\n",
    "y_pred = X @ theta\n",
    "theta0, theta1, theta2, mse = theta[0], theta[1], theta[2], numpy.mean((Y - y_pred)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f099afd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q2'] = [theta0, theta1, theta2, mse]\n",
    "assertFloatList(answers['Q2'], 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1147c4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "78ef0f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(datum, deg):\n",
    "    # feature for a specific polynomial degree\n",
    "    features = [1]\n",
    "    for d in range(1, deg+1):\n",
    "        features.append(datum['review_text'].count('!') ** d)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "75028699",
   "metadata": {},
   "outputs": [],
   "source": [
    "mses = []\n",
    "for i in range(1, 6):\n",
    "    X = [feature(d, i) for d in dataset]\n",
    "    Y = [d['rating'] for d in dataset]\n",
    "    theta = numpy.linalg.lstsq(X, Y)[0]\n",
    "    y_pred = X @ theta\n",
    "    mses.append(numpy.mean((Y - y_pred)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "559faac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q3'] = mses\n",
    "assertFloatList(answers['Q3'], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dcbb8263",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e91bc048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(datum, deg):\n",
    "    # feature for a specific polynomial degree\n",
    "    features = [1]\n",
    "    for d in range(1, deg+1):\n",
    "        features.append(datum['review_text'].count('!') ** d)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ac69c439",
   "metadata": {},
   "outputs": [],
   "source": [
    "mses = []\n",
    "for i in range(1, 6):\n",
    "    X = [feature(d, i) for d in dataset]\n",
    "    X_train = X[:len(X)//2] # first half for training\n",
    "    X_test = X[len(X)//2:] # second half for test\n",
    "    Y = [d['rating'] for d in dataset]\n",
    "    Y_train = Y[:len(Y)//2] # first half for training\n",
    "    Y_test = Y[len(Y)//2:] # second half for tes\n",
    "    \n",
    "    theta = numpy.linalg.lstsq(X_train, Y_train)[0]\n",
    "    y_pred = X_test @ theta\n",
    "    mses.append(numpy.mean((Y_test - y_pred)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd505ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q4'] = mses\n",
    "assertFloatList(answers['Q4'], 5)\n",
    "mses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2fa286a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "81dcc36d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [1]*10000\n",
    "Y = [d['rating'] for d in dataset]\n",
    "theta = numpy.median(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b3a2e9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = numpy.mean(abs(Y - theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d71a47ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8923"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers['Q5'] = mae\n",
    "assertFloat(answers['Q5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf84f30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "19b5b795",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"beer_50000.json\")\n",
    "dataset = []\n",
    "for l in f:\n",
    "    if 'user/gender' in l:\n",
    "        dataset.append(eval(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "299d4fee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review/appearance': 4.0,\n",
       " 'beer/style': 'American Double / Imperial IPA',\n",
       " 'review/palate': 4.0,\n",
       " 'review/taste': 4.5,\n",
       " 'beer/name': 'Cauldron DIPA',\n",
       " 'review/timeUnix': 1293735206,\n",
       " 'user/gender': 'Male',\n",
       " 'user/birthdayRaw': 'Jun 16, 1901',\n",
       " 'beer/ABV': 7.7,\n",
       " 'beer/beerId': '64883',\n",
       " 'user/birthdayUnix': -2163081600,\n",
       " 'beer/brewerId': '1075',\n",
       " 'review/timeStruct': {'isdst': 0,\n",
       "  'mday': 30,\n",
       "  'hour': 18,\n",
       "  'min': 53,\n",
       "  'sec': 26,\n",
       "  'mon': 12,\n",
       "  'year': 2010,\n",
       "  'yday': 364,\n",
       "  'wday': 3},\n",
       " 'user/ageInSeconds': 3581417047,\n",
       " 'review/overall': 4.0,\n",
       " 'review/text': \"According to the website, the style for the Caldera Cauldron changes every year. The current release is a DIPA, which frankly is the only cauldron I'm familiar with (it was an IPA/DIPA the last time I ordered a cauldron at the horsebrass several years back). In any event... at the Horse Brass yesterday.\\t\\tThe beer pours an orange copper color with good head retention and lacing. The nose is all hoppy IPA goodness, showcasing a huge aroma of dry citrus, pine and sandlewood. The flavor profile replicates the nose pretty closely in this West Coast all the way DIPA. This DIPA is not for the faint of heart and is a bit much even for a hophead like myslf. The finish is quite dry and hoppy, and there's barely enough sweet malt to balance and hold up the avalanche of hoppy bitterness in this beer. Mouthfeel is actually fairly light, with a long, persistentely bitter finish. Drinkability is good, with the alcohol barely noticeable in this well crafted beer. Still, this beer is so hugely hoppy/bitter, it's really hard for me to imagine ordering more than a single glass. Regardless, this is a very impressive beer from the folks at Caldera.\",\n",
       " 'user/profileName': 'johnmichaelsen',\n",
       " 'review/aroma': 4.5}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e5239721",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(datum):\n",
    "    return [1, datum['review/text'].count('!')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cf95bec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [feature(d) for d in dataset if d['user/gender'] in ['Male', 'Female']]\n",
    "y = [1 if d['user/gender'] == 'Female' else 0 for d in dataset if d['user/gender'] in ['Male', 'Female']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e0ce9c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = linear_model.LogisticRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "y_pred = model.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e70e5a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "TN, FP, FN, TP = confusion_matrix(y, y_pred).ravel()\n",
    "\n",
    "# Calculate BER\n",
    "total_male = TN + FP\n",
    "total_female = TP + FN\n",
    "BER = 0.5 * (FP / total_male + FN / total_female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0c35d20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q6'] = [TP, TN, FP, FN, BER]\n",
    "assertFloatList(answers['Q6'], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f066f3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d24c241f",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_model = linear_model.LogisticRegression(class_weight='balanced')\n",
    "balanced_model.fit(X, y)\n",
    "\n",
    "y_pred = balanced_model.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "efacdab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TN, FP, FN, TP = confusion_matrix(y, y_pred).ravel()\n",
    "BER = 0.5 * (FP / (TN + FP) + FN / (TP + FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0622704c",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers[\"Q7\"] = [TP, TN, FP, FN, BER]\n",
    "assertFloatList(answers['Q7'], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e622c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9b6bcea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(y_true, y_scores, k):\n",
    "    sorted_indices = sorted(range(len(y_scores)), key=lambda i: y_scores[i], reverse=True)\n",
    "    top_k = sorted_indices[:k]\n",
    "    # Count true positives\n",
    "    true_positives = sum([y_true[i] for i in top_k])\n",
    "    return true_positives / k\n",
    "\n",
    "y_scores = balanced_model.decision_function(X)\n",
    "\n",
    "# Calculate Precision@K for K âˆˆ [1, 10, 100, 1000, 10000]\n",
    "k_values = [1, 10, 100, 1000, 10000]\n",
    "precisionList = []\n",
    "for k in k_values:\n",
    "    if k <= len(y):\n",
    "        precisionList.append(precision_at_k(y, y_scores, k))\n",
    "    else:\n",
    "        precisionList.append(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "764513e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q8'] = precisionList\n",
    "assertFloatList(answers['Q8'], 5) #List of five floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d557ab88",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"answers_hw1.txt\", 'w') # Write your answers to a file\n",
    "f.write(str(answers) + '\\n')\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
