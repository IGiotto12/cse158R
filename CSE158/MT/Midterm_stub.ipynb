{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fadc0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gzip\n",
    "import math\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn import linear_model\n",
    "import random\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdcf1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assertFloat(x):\n",
    "    assert type(float(x)) == float\n",
    "\n",
    "def assertFloatList(items, N):\n",
    "    assert len(items) == N\n",
    "    assert [type(float(x)) for x in items] == [float]*N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a8d119",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a6d4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://cseweb.ucsd.edu/classes/fa24/cse258-b/files/steam.json.gz\n",
    "z = gzip.open(\"steam.json.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d2ef14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for l in z:\n",
    "    d = eval(l)\n",
    "    dataset.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46a06fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93e80cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c37e48b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(y, ypred):\n",
    "    diffs = [(a-b)**2 for (a,b) in zip(y,ypred)]\n",
    "    return sum(diffs) / len(diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d90c72f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat1(d):\n",
    "    return [1, len(d['text'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4e6ec8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [feat1(d) for d in dataset]\n",
    "y = [d['hours'] for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b74b4f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = linear_model.LinearRegression(fit_intercept=False)\n",
    "mod.fit(X, y)\n",
    "\n",
    "y_pred = mod.predict(X)\n",
    "mse1 = MSE(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f32ed5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q1'] = [float(mod.coef_[1]), float(mse1)] # Remember to cast things to float rather than (e.g.) np.float64\n",
    "assertFloatList(answers['Q1'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e26bb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99a2aba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTrain = dataset[:int(len(dataset)*0.8)]\n",
    "dataTest = dataset[int(len(dataset)*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89ec0d0b-54be-4e77-9970-ce32d30c787a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [feat1(d) for d in dataTrain]\n",
    "y_train = [d['hours'] for d in dataTrain]\n",
    "\n",
    "X_test = [feat1(d) for d in dataTest]\n",
    "y_test = [d['hours'] for d in dataTest]\n",
    "\n",
    "mod = linear_model.LinearRegression(fit_intercept=False)\n",
    "mod.fit(X, y)\n",
    "\n",
    "y_pred = mod.predict(X_test)\n",
    "mse2 = MSE(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0620a9b-f9e9-4c43-846d-5d66eb0254b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "under = 0\n",
    "over = 0\n",
    "\n",
    "for test, pred in zip(y_test, y_pred):\n",
    "    if pred > test:\n",
    "        over += 1\n",
    "    if pred < test:\n",
    "        under += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a5d7a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q2'] = [mse2, under, over]\n",
    "assertFloatList(answers['Q2'], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a690f9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e524edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = y[:]\n",
    "y2.sort()\n",
    "perc90 = y2[int(len(y2)*0.9)] # 90th percentile\n",
    "\n",
    "X3a = []\n",
    "y3a = []\n",
    "\n",
    "for d in dataTrain:\n",
    "    if d['hours'] <= perc90:\n",
    "        X3a.append(feat1(d))\n",
    "        y3a.append(d['hours'])\n",
    "\n",
    "mod3a = linear_model.LinearRegression(fit_intercept=False)\n",
    "mod3a.fit(X3a,y3a)\n",
    "pred3a = mod3a.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90de762d-2a60-4e3b-ba47-8f8d71a7936e",
   "metadata": {},
   "outputs": [],
   "source": [
    "under3a = 0\n",
    "over3a = 0\n",
    "\n",
    "for test, pred in zip(y_test, pred3a):\n",
    "    if pred > test:\n",
    "        over3a += 1\n",
    "    if pred < test:\n",
    "        under3a += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6a7160f-3836-4a36-be1b-4bb928c08f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79e7d70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y3b = [d['hours_transformed'] for d in dataTrain]\n",
    "\n",
    "mod3b = linear_model.LinearRegression(fit_intercept=False)\n",
    "mod3b.fit(X_train,y3b)\n",
    "pred3b = mod3b.predict(X_test)\n",
    "pred3b_original = [2 ** pred - 1 for pred in pred3b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f50dd269-673b-4706-9d25-fb5a1ffdcfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "under3b = 0\n",
    "over3b = 0\n",
    "\n",
    "for test, pred in zip(y_test, pred3b_original):\n",
    "    if pred > test:\n",
    "        over3b += 1\n",
    "    if pred < test:\n",
    "        under3b += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf8370bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f57ca618",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta0 = mod.coef_[0]\n",
    "\n",
    "median_length = np.median([len(d['text']) for d in dataTrain])\n",
    "median_hours = np.median([d['hours'] for d in dataTrain])\n",
    "\n",
    "theta1 = (median_hours - theta0) / median_length\n",
    "\n",
    "pred3c = [theta0 + theta1 * len(d['text']) for d in dataTest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a8b7b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "under3c = 0\n",
    "over3c = 0\n",
    "\n",
    "for test, pred in zip(y_test, pred3c):\n",
    "    if pred > test:\n",
    "        over3c += 1\n",
    "    if pred < test:\n",
    "        under3c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "017eeef8-6a78-4872-b6b5-b297abe6213c",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q3'] = [under3a, over3a, under3b, over3b, under3c, over3c]\n",
    "assertFloatList(answers['Q3'], 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "15645595-b793-42ae-bf08-51ed4aa11b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0968ced0-1b35-4032-b4bf-ee4d0c32182f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [1 if d['hours'] > median_hours else 0 for d in dataTrain]\n",
    "ytest = [1 if d['hours'] > median_hours else 0 for d in dataTest]\n",
    "\n",
    "\n",
    "mod_log = linear_model.LogisticRegression(C=1)\n",
    "mod_log.fit(X_train,y)\n",
    "pred4 = mod_log.predict(X_test) # Binary vector of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82e3f6ec-8911-4249-927e-c78dc891197f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def Calc_BER(predictions, y):\n",
    "    TN, FP, FN, TP = confusion_matrix(y, predictions).ravel()\n",
    "    ber = 0.5 * ((FP / (TN + FP) if (TN + FP) > 0 else 0) + \n",
    "                 (FN / (TP + FN) if (TP + FN) > 0 else 0))\n",
    "    return ber\n",
    "\n",
    "TN, FP, FN, TP = confusion_matrix(ytest, pred4).ravel()\n",
    "BER = Calc_BER(pred4, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "33548639-8b44-402d-940f-256ace3e35bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q4'] = [TP, TN, FP, FN, BER]\n",
    "assertFloatList(answers['Q4'], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b357a12a-a71c-4562-a407-5fdaaece6a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ac8a32a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "under5 = 0\n",
    "over5 = 0\n",
    "\n",
    "for test, pred in zip(ytest, pred4):\n",
    "    if pred > test:\n",
    "        over5 += 1\n",
    "    if pred < test:\n",
    "        under5 += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9094734d-209b-44ac-8459-2bcbc8d25e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q5'] = [over5, under5]\n",
    "assertFloatList(answers['Q5'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8b4a2fd5-6773-4bc2-90ee-faeb629c6823",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "01bd99c6-acc7-4d85-81a1-9da9a14bd40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part (a)\n",
    "train_early = [d for d in dataTrain if int(d['date'][:4]) <= 2014]\n",
    "test_early = [d for d in dataTest if int(d['date'][:4]) <= 2014]\n",
    "\n",
    "median_hours_early = np.median([d['hours'] for d in train_early])\n",
    "X2014train = [feat1(d) for d in train_early]\n",
    "y2014train = [1 if d['hours'] > median_hours_early else 0 for d in train_early]\n",
    "\n",
    "X2014test = [feat1(d) for d in test_early]\n",
    "y2014test = [1 if d['hours'] > median_hours_early else 0 for d in test_early]\n",
    "\n",
    "mod_log = linear_model.LogisticRegression(C=1)\n",
    "mod_log.fit(X2014train, y2014train)\n",
    "pred2014 = mod_log.predict(X2014test)\n",
    "\n",
    "BER_A = Calc_BER(pred2014, y2014test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c3aee3be-0de4-4087-b8fa-ccd825604690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part (b)\n",
    "train_later = [d for d in dataTrain if int(d['date'][:4]) >= 2015]\n",
    "test_later = [d for d in dataTest if int(d['date'][:4]) >= 2015]\n",
    "\n",
    "median_hours_later = np.median([d['hours'] for d in train_later])\n",
    "X2015train = [feat1(d) for d in train_later]\n",
    "y2015train = [1 if d['hours'] > median_hours_later else 0 for d in train_later]\n",
    "\n",
    "X2015test = [feat1(d) for d in test_later]\n",
    "y2015test = [1 if d['hours'] > median_hours_later else 0 for d in test_later]\n",
    "\n",
    "mod_log = linear_model.LogisticRegression(C=1)\n",
    "mod_log.fit(X2015train, y2015train)\n",
    "pred2015 = mod_log.predict(X2015test)\n",
    "\n",
    "BER_B = Calc_BER(pred2015, y2015test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "163e4ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part (c)\n",
    "mod_log = linear_model.LogisticRegression(C=1)\n",
    "mod_log.fit(X2014train, y2014train)\n",
    "predc = mod_log.predict(X2015test)\n",
    "\n",
    "BER_C = Calc_BER(predc, y2015test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5ceb9505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part (d)\n",
    "mod_log = linear_model.LogisticRegression(C=1)\n",
    "mod_log.fit(X2015train, y2015train)\n",
    "predd= mod_log.predict(X2014test)\n",
    "\n",
    "BER_D = Calc_BER(predd, y2014test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "77349259-dc23-4051-a7af-d8becaf9a0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q6'] = [BER_A, BER_B, BER_C, BER_D]\n",
    "assertFloatList(answers['Q6'], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3b4c89bb-4a6e-4ff4-8178-a8519bb72151",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0a7f0b9c-307d-4376-aabc-300882bb71f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful data structures\n",
    "usersPerItem = defaultdict(set) # Maps an item to the users who rated it\n",
    "itemsPerUser = defaultdict(set) # Maps a user to the items that they rated\n",
    "reviewsPerUser = defaultdict(list)\n",
    "reviewsPerItem = defaultdict(list)\n",
    "ratings = {}\n",
    "\n",
    "dataTrain = dataset[:int(len(dataset)*0.8)]\n",
    "dataTest = dataset[int(len(dataset)*0.8):]\n",
    "\n",
    "for d in dataTrain:\n",
    "    user, item = d['userID'], d['gameID']\n",
    "    usersPerItem[item].add(user)\n",
    "    itemsPerUser[user].add(item)\n",
    "\n",
    "# Populate the dictionaries from training data\n",
    "for d in dataTrain:\n",
    "    user = d['userID']\n",
    "    game = d['gameID']\n",
    "    hours_transformed = d['hours_transformed']\n",
    "    review_date = d['date']\n",
    "    \n",
    "    # Append review data to each user's list\n",
    "    reviewsPerUser[user].append({\n",
    "        'gameID': game, \n",
    "        'hours_transformed': hours_transformed,\n",
    "        'date': review_date\n",
    "    })\n",
    "    \n",
    "    # Append review data to each item's list\n",
    "    reviewsPerItem[game].append({\n",
    "        'userID': user, \n",
    "        'hours_transformed': hours_transformed,\n",
    "        'date': review_date\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8c59b51b-4d40-489f-8f02-6c7b646be571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jaccard similarity\n",
    "def Jaccard(s1, s2):\n",
    "    intersection = len(s1 & s2)\n",
    "    union = len(s1 | s2)\n",
    "    return intersection / union if union != 0 else 0\n",
    "\n",
    "# find N most similar users\n",
    "def mostSimilar(user, N):\n",
    "    similarity = []\n",
    "    target_items = itemsPerUser[user]\n",
    "\n",
    "    for other_user, items in itemsPerUser.items():\n",
    "        if other_user != user:\n",
    "            sim = Jaccard(target_items, items)\n",
    "            similarity.append((sim, other_user))\n",
    "\n",
    "    most_similar_users = sorted(similarity, reverse=True)[:N]\n",
    "    return most_similar_users\n",
    "\n",
    "top10similar = mostSimilar(dataset[0]['userID'], 10)\n",
    "\n",
    "first = top10similar[0][0]\n",
    "tenth = top10similar[-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c40046cf-4900-4efb-b161-60e62dd0705f",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q7'] = [first, tenth]\n",
    "assertFloatList(answers['Q7'], 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "de1c320a-37b2-42e3-9362-4294b31047f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "358db1e9-d9ad-432e-a233-74dc1ab44279",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_avg = np.mean([d['hours_transformed'] for d in dataTrain])\n",
    "\n",
    "def user_to_user_predict(user, item):\n",
    "    weighted_sum = 0\n",
    "    sum_of_weights = 0\n",
    "    \n",
    "    if user not in reviewsPerUser:\n",
    "        return global_avg\n",
    "    if item not in reviewsPerItem:\n",
    "        return global_avg\n",
    "\n",
    "    # Iterate through other users who reviewed the same item\n",
    "    for review in reviewsPerItem[item]:\n",
    "        other_user = review['userID']\n",
    "        if other_user != user:\n",
    "            # Calculate Jaccard similarity between users\n",
    "            sim = Jaccard(set(d['gameID'] for d in reviewsPerUser[user]),\n",
    "                          set(d['gameID'] for d in reviewsPerUser[other_user]))\n",
    "            \n",
    "            weighted_sum += sim * review['hours_transformed']\n",
    "            sum_of_weights += sim\n",
    "\n",
    "    return weighted_sum / sum_of_weights if sum_of_weights > 0 else global_avg\n",
    "\n",
    "def item_to_item_predict(user, item):\n",
    "    weighted_sum = 0\n",
    "    sum_of_weights = 0\n",
    "\n",
    "    if item not in reviewsPerItem:\n",
    "        return global_avg\n",
    "\n",
    "    if user not in reviewsPerUser:\n",
    "        return global_avg\n",
    "\n",
    "    # Iterate through other items the user has reviewed\n",
    "    for review in reviewsPerUser[user]:\n",
    "        other_item = review['gameID']\n",
    "        if other_item != item:\n",
    "            # Calculate Jaccard similarity between items\n",
    "            sim = Jaccard(set(d['userID'] for d in reviewsPerItem[item]),\n",
    "                          set(d['userID'] for d in reviewsPerItem[other_item]))\n",
    "            \n",
    "            weighted_sum += sim * review['hours_transformed']\n",
    "            sum_of_weights += sim\n",
    "\n",
    "    return weighted_sum / sum_of_weights if sum_of_weights > 0 else global_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3043fb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MSE for each predictor on the test set\n",
    "def compute_mse(predict_fn, test_data):\n",
    "    errors = []\n",
    "    for d in test_data:\n",
    "        # Call predict_fn with only userID and gameID\n",
    "        pred = predict_fn(d['userID'], d['gameID'])\n",
    "        errors.append((d['hours_transformed'] - pred) ** 2)\n",
    "    return np.mean(errors)\n",
    "\n",
    "MSEU = compute_mse(user_to_user_predict, dataTest)\n",
    "MSEI = compute_mse(item_to_item_predict, dataTest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "55d2d046-6faa-4a73-ae47-f013aaa51d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q8'] = [MSEU, MSEI]\n",
    "assertFloatList(answers['Q8'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2adb115b-2007-47a6-a29f-096f287cf434",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "16be0fa6-d7c9-459c-bf94-7ccd84fa24df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def user_to_user_predict_with_time(user, item):\n",
    "    weighted_sum = 0\n",
    "    sum_of_weights = 0\n",
    "    global_avg = np.mean([d['hours_transformed'] for d in dataTrain])\n",
    "\n",
    "    if user not in reviewsPerUser:\n",
    "        return global_avg\n",
    "    if item not in reviewsPerItem:\n",
    "        return global_avg\n",
    "\n",
    "    target_review = next((r for r in reviewsPerUser[user] if r['gameID'] == item), None)\n",
    "    if target_review is None:\n",
    "        return global_avg\n",
    "    target_year = target_review['date'].year\n",
    "\n",
    "    for review in reviewsPerItem[item]:\n",
    "        other_user = review['userID']\n",
    "        if other_user != user:\n",
    "            # Calculate Jaccard similarity between users\n",
    "            sim = Jaccard(set(d['gameID'] for d in reviewsPerUser[user]),\n",
    "                          set(d['gameID'] for d in reviewsPerUser[other_user]))\n",
    "\n",
    "            other_year = review['date'].year\n",
    "            time_decay = math.exp(-abs(target_year - other_year))\n",
    "\n",
    "            weighted_sum += sim * time_decay * review['hours_transformed']\n",
    "            sum_of_weights += sim * time_decay\n",
    "\n",
    "    return weighted_sum / sum_of_weights if sum_of_weights > 0 else global_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0c586dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE9 = compute_mse(user_to_user_predict_with_time, dataTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "57fdbdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q9'] = [MSE9]\n",
    "assertFloatList(answers['Q9'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "de71bdd6-92d8-430d-b419-7e37e3ddc701",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"float\" in str(answers) or \"int\" in str(answers):\n",
    "    print(\"it seems that some of your answers are not native python ints/floats;\")\n",
    "    print(\"the autograder will not be able to read your solution unless you convert them to ints/floats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d3fb9831-179f-4354-b4f0-48a4ea5b767c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"answers_midterm.txt\", 'w')\n",
    "f.write(str(answers) + '\\n')\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
